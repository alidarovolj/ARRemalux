#import <Foundation/Foundation.h>
#import <CoreML/CoreML.h>
#import <Vision/Vision.h>
#import <AVFoundation/AVFoundation.h>
#import <Accelerate/Accelerate.h>

// ====================================
// CoreML Depth Estimation Plugin –¥–ª—è Unity
// Depth Anything V2 - Monocular Depth Estimation
// ====================================

static MLModel* depthModel = nil;
static VNImageRequestHandler* requestHandler = nil;
static CVPixelBufferRef currentPixelBuffer = nil;

// –†–µ–∑—É–ª—å—Ç–∞—Ç depth estimation (512x512 float values)
static NSMutableData* depthMapData = nil;

#ifdef __cplusplus
extern "C" {
#endif

// ====================================
// Initialization
// ====================================

bool CoreMLDepth_Initialize(const char* modelPath) {
    NSLog(@"[CoreMLDepth] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –º–æ–¥–µ–ª—å—é: %s", modelPath);
    
    NSString* path = [NSString stringWithUTF8String:modelPath];
    NSURL* modelURL = [NSURL fileURLWithPath:path];
    
    NSError* error = nil;
    
    // –ó–∞–≥—Ä—É–∂–∞–µ–º CoreML –º–æ–¥–µ–ª—å
    MLModelConfiguration* config = [[MLModelConfiguration alloc] init];
    config.computeUnits = MLComputeUnitsAll; // CPU + GPU + Neural Engine
    
    depthModel = [MLModel modelWithContentsOfURL:modelURL configuration:config error:&error];
    
    if (error != nil || depthModel == nil) {
        NSLog(@"[CoreMLDepth] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
        return false;
    }
    
    NSLog(@"[CoreMLDepth] ‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!");
    NSLog(@"[CoreMLDepth] Model Description: \n%@", depthModel.modelDescription);
    
    // –í—ã–¥–µ–ª—è–µ–º –±—É—Ñ–µ—Ä –¥–ª—è depth map (512x512 floats = 262144 floats = 1048576 bytes)
    depthMapData = [[NSMutableData alloc] initWithLength:512 * 512 * sizeof(float)];
    
    return true;
}

// ====================================
// Depth Estimation from Current AR Frame
// ====================================

void CoreMLDepth_EstimateDepth(float* outputBuffer, int bufferSize, int resolution) {
    if (depthModel == nil) {
        NSLog(@"[CoreMLDepth] ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!");
        return;
    }
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å AR frame
    CVPixelBufferRef pixelBuffer = currentPixelBuffer;
    
    if (pixelBuffer == nil) {
        // –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - –µ—â–µ –Ω–µ—Ç frames, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        static int warningCount = 0;
        if (warningCount < 3) {
            NSLog(@"[CoreMLDepth] ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ AR frame... (–ø–æ–ø—ã—Ç–∫–∞ %d)", ++warningCount);
        }
        return;
    }
    
    CFTimeInterval startTime = CACurrentMediaTime();
    
    @try {
        // –°–æ–∑–¥–∞–µ–º VNImageRequestHandler
        VNImageRequestHandler* handler = [[VNImageRequestHandler alloc] 
            initWithCVPixelBuffer:pixelBuffer 
            options:@{}];
        
        // –°–æ–∑–¥–∞–µ–º CoreML Vision Request
        VNCoreMLModel* visionModel = [VNCoreMLModel modelForMLModel:depthModel error:nil];
        VNCoreMLRequest* request = [[VNCoreMLRequest alloc] initWithModel:visionModel];
        
        // –í—ã–ø–æ–ª–Ω—è–µ–º inference
        NSError* error = nil;
        [handler performRequests:@[request] error:&error];
        
        if (error != nil) {
            NSLog(@"[CoreMLDepth] ‚ùå –û—à–∏–±–∫–∞ inference: %@", error.localizedDescription);
            return;
        }
        
        // –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        VNObservation* observation = request.results.firstObject;
        
        if ([observation isKindOfClass:[VNPixelBufferObservation class]]) {
            VNPixelBufferObservation* pixelBufferObs = (VNPixelBufferObservation*)observation;
            CVPixelBufferRef depthBuffer = pixelBufferObs.pixelBuffer;
            
            // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º depth buffer –≤ float array
            CVPixelBufferLockBaseAddress(depthBuffer, kCVPixelBufferLock_ReadOnly);
            
            void* baseAddress = CVPixelBufferGetBaseAddress(depthBuffer);
            size_t width = CVPixelBufferGetWidth(depthBuffer);
            size_t height = CVPixelBufferGetHeight(depthBuffer);
            
            // –ö–æ–ø–∏—Ä—É–µ–º depth values
            float* depthData = (float*)baseAddress;
            memcpy(outputBuffer, depthData, bufferSize * sizeof(float));
            
            CVPixelBufferUnlockBaseAddress(depthBuffer, kCVPixelBufferLock_ReadOnly);
            
            CFTimeInterval elapsedTime = (CACurrentMediaTime() - startTime) * 1000.0;
            NSLog(@"[CoreMLDepth] ‚ö° Inference time: %.1f ms", elapsedTime);
            NSLog(@"[CoreMLDepth ‚Üí Unity] ‚úÖ Depth map ready (resolution: %zux%zu)", width, height);
        }
    }
    @catch (NSException* exception) {
        NSLog(@"[CoreMLDepth] üí• Exception: %@", exception.reason);
    }
}

// ====================================
// Helper: Set Current AR Frame
// ====================================

void CoreMLDepth_SetARFrame(CVPixelBufferRef pixelBuffer) {
    if (currentPixelBuffer != nil) {
        CVPixelBufferRelease(currentPixelBuffer);
    }
    currentPixelBuffer = CVPixelBufferRetain(pixelBuffer);
}

// ====================================
// Cleanup
// ====================================

void CoreMLDepth_Cleanup() {
    NSLog(@"[CoreMLDepth] Cleanup...");
    
    if (currentPixelBuffer != nil) {
        CVPixelBufferRelease(currentPixelBuffer);
        currentPixelBuffer = nil;
    }
    
    depthModel = nil;
    requestHandler = nil;
    depthMapData = nil;
    
    NSLog(@"[CoreMLDepth] ‚úÖ Cleanup –∑–∞–≤–µ—Ä—à–µ–Ω");
}

// ====================================
// Status Check
// ====================================

bool CoreMLDepth_IsInitialized() {
    return (depthModel != nil);
}

#ifdef __cplusplus
}
#endif

