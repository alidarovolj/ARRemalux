//
//  CoreMLSegmentation.mm
//  ARRemalux - CoreML Semantic Segmentation Plugin for Unity
//
//  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç SegFormer-B0 –º–æ–¥–µ–ª—å –¥–ª—è pixel-level –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ü–µ–Ω—ã
//  –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 150 –∫–ª–∞—Å—Å–æ–≤ ADE20K dataset (wall, door, person, furniture, etc.)
//

#import <Foundation/Foundation.h>
#import <CoreML/CoreML.h>
#import <Vision/Vision.h>
#import <ARKit/ARKit.h>
#import <UIKit/UIKit.h>

// ===============================
// MARK: - CoreML Segmentation Class
// ===============================

@interface CoreMLSegmentation : NSObject

@property (nonatomic, strong) MLModel *mlModel;
@property (nonatomic, strong) VNCoreMLModel *visionModel;
@property (nonatomic, strong) VNCoreMLRequest *segmentationRequest;
@property (nonatomic, assign) BOOL isInitialized;

+ (instancetype)sharedInstance;
- (BOOL)initializeWithModelPath:(NSString *)modelPath;
- (NSData *)segmentImage:(UIImage *)image withResolution:(NSInteger)resolution;
- (void)cleanup;

@end

@implementation CoreMLSegmentation

// Singleton instance
+ (instancetype)sharedInstance {
    static CoreMLSegmentation *instance = nil;
    static dispatch_once_t onceToken;
    dispatch_once(&onceToken, ^{
        instance = [[CoreMLSegmentation alloc] init];
    });
    return instance;
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CoreML –º–æ–¥–µ–ª–∏
- (BOOL)initializeWithModelPath:(NSString *)modelPath {
    NSLog(@"[CoreMLSegmentation] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –º–æ–¥–µ–ª—å—é: %@", modelPath);
    
    @try {
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        if (![[NSFileManager defaultManager] fileExistsAtPath:modelPath]) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: %@", modelPath);
            return NO;
        }
        
        // –ó–∞–≥—Ä—É–∑–∫–∞ CoreML –º–æ–¥–µ–ª–∏
        NSURL *modelURL = [NSURL fileURLWithPath:modelPath];
        NSError *error = nil;
        
        // –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        NSURL *compiledURL = [MLModel compileModelAtURL:modelURL error:&error];
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
            return NO;
        }
        
        // –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        self.mlModel = [MLModel modelWithContentsOfURL:compiledURL error:&error];
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
            return NO;
        }
        
        // –°–æ–∑–¥–∞–Ω–∏–µ Vision –º–æ–¥–µ–ª–∏
        self.visionModel = [VNCoreMLModel modelForMLModel:self.mlModel error:&error];
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Vision –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
            return NO;
        }
        
        // –°–æ–∑–¥–∞–Ω–∏–µ Vision request –¥–ª—è segmentation
        self.segmentationRequest = [[VNCoreMLRequest alloc] initWithModel:self.visionModel];
        self.segmentationRequest.imageCropAndScaleOption = VNImageCropAndScaleOptionScaleFill;
        
        self.isInitialized = YES;
        NSLog(@"[CoreMLSegmentation] ‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!");
        
        // –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        NSLog(@"[CoreMLSegmentation] Model Description: %@", self.mlModel.modelDescription);
        
        return YES;
    }
    @catch (NSException *exception) {
        NSLog(@"[CoreMLSegmentation] ‚ùå Exception –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: %@", exception.reason);
        return NO;
    }
}

// –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- (NSData *)segmentImage:(UIImage *)image withResolution:(NSInteger)resolution {
    if (!self.isInitialized) {
        NSLog(@"[CoreMLSegmentation] ‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!");
        return nil;
    }
    
    @try {
        // –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è inference
        CFAbsoluteTime startTime = CFAbsoluteTimeGetCurrent();
        
        // –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ resolution√óresolution
        UIImage *resizedImage = [self resizeImage:image toSize:CGSizeMake(resolution, resolution)];
        
        // –°–æ–∑–¥–∞–Ω–∏–µ VNImageRequestHandler
        CIImage *ciImage = [CIImage imageWithCGImage:resizedImage.CGImage];
        VNImageRequestHandler *handler = [[VNImageRequestHandler alloc] 
                                          initWithCIImage:ciImage 
                                          options:@{}];
        
        // –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ inference
        NSError *error = nil;
        [handler performRequests:@[self.segmentationRequest] error:&error];
        
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ inference: %@", error.localizedDescription);
            return nil;
        }
        
        // –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        VNCoreMLFeatureValueObservation *observation = self.segmentationRequest.results.firstObject;
        if (!observation) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ inference");
            return nil;
        }
        
        // –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑ MLMultiArray
        MLMultiArray *segmentationMap = observation.featureValue.multiArrayValue;
        
        // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è MLMultiArray ‚Üí byte array
        NSData *maskData = [self convertMultiArrayToByteArray:segmentationMap 
                                                  withResolution:resolution];
        
        // –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
        CFAbsoluteTime elapsedTime = CFAbsoluteTimeGetCurrent() - startTime;
        NSLog(@"[CoreMLSegmentation] ‚ö° Inference time: %.1f ms", elapsedTime * 1000.0);
        
        return maskData;
    }
    @catch (NSException *exception) {
        NSLog(@"[CoreMLSegmentation] ‚ùå Exception –ø—Ä–∏ segmentation: %@", exception.reason);
        return nil;
    }
}

// –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- (UIImage *)resizeImage:(UIImage *)image toSize:(CGSize)newSize {
    UIGraphicsBeginImageContextWithOptions(newSize, NO, 1.0);
    [image drawInRect:CGRectMake(0, 0, newSize.width, newSize.height)];
    UIImage *resizedImage = UIGraphicsGetImageFromCurrentImageContext();
    UIGraphicsEndImageContext();
    return resizedImage;
}

// –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è MLMultiArray ‚Üí byte array (–º–∞—Å–∫–∞ –∫–ª–∞—Å—Å–æ–≤)
- (NSData *)convertMultiArrayToByteArray:(MLMultiArray *)multiArray 
                          withResolution:(NSInteger)resolution {
    NSInteger totalElements = resolution * resolution;
    NSMutableData *data = [NSMutableData dataWithLength:totalElements];
    uint8_t *bytes = (uint8_t *)data.mutableBytes;
    
    // SegFormer –≤—ã–¥–∞—ë—Ç argmax –∫–ª–∞—Å—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è
    // –§–æ—Ä–º–∞ –≤—ã–≤–æ–¥–∞: [1, num_classes, height, width]
    // –ù–∞–º –Ω—É–∂–µ–Ω argmax –ø–æ –æ—Å–∏ num_classes
    
    for (NSInteger i = 0; i < totalElements; i++) {
        // –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        // –î–ª—è SegFormer —ç—Ç–æ —É–∂–µ argmax –≤—ã–≤–æ–¥
        NSNumber *classId = [multiArray objectAtIndexedSubscript:i];
        bytes[i] = [classId unsignedCharValue];
    }
    
    return data;
}

// –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
- (void)cleanup {
    self.mlModel = nil;
    self.visionModel = nil;
    self.segmentationRequest = nil;
    self.isInitialized = NO;
    NSLog(@"[CoreMLSegmentation] üßπ –†–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã");
}

@end

// ===============================
// MARK: - Unity C Bridge
// ===============================

extern "C" {
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    bool CoreML_Initialize(const char* modelPath) {
        @autoreleasepool {
            NSString *path = [NSString stringWithUTF8String:modelPath];
            NSLog(@"[Unity ‚Üí CoreML] Initialize called with path: %@", path);
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            BOOL success = [segmentation initializeWithModelPath:path];
            
            return success;
        }
    }
    
    // –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ AR frame
    static CVPixelBufferRef currentARFrame = nil;
    
    // –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: Unity –≤—ã–∑—ã–≤–∞–µ—Ç –µ—ë –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä, –ø–µ—Ä–µ–¥–∞–≤–∞—è —Ç–µ–∫—Å—Ç—É—Ä—É –∫–∞–º–µ—Ä—ã
    void CoreML_SetARFrame(CVPixelBufferRef pixelBuffer) {
        @autoreleasepool {
            // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–∞–¥—Ä
            if (currentARFrame != nil) {
                CVPixelBufferRelease(currentARFrame);
            }
            
            // –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π –∫–∞–¥—Ä
            currentARFrame = pixelBuffer;
            if (currentARFrame != nil) {
                CVPixelBufferRetain(currentARFrame);
            }
        }
    }
    
    // –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ç–µ–∫—É—â–µ–≥–æ AR –∫–∞–¥—Ä–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–û - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é –∫–∞–º–µ—Ä—É!)
    void CoreML_SegmentCurrentFrame(uint8_t* outputBuffer, int bufferSize, int resolution) {
        @autoreleasepool {
            NSLog(@"[Unity ‚Üí CoreML] SegmentCurrentFrame called (resolution: %d)", resolution);
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            
            if (!segmentation.isInitialized) {
                NSLog(@"[CoreML] ‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!");
                return;
            }
            
            // –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π AR frame!
            CVPixelBufferRef pixelBuffer = currentARFrame;
            
            if (pixelBuffer == nil) {
                // –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - –µ—â–µ –Ω–µ—Ç frames, —Å–æ–∑–¥–∞—ë–º –∑–∞–≥–ª—É—à–∫—É
                static int warningCount = 0;
                if (warningCount < 3) {
                    NSLog(@"[CoreML] ‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ AR frame... (–ø–æ–ø—ã—Ç–∫–∞ %d)", ++warningCount);
                }
                
                // –°–æ–∑–¥–∞—ë–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∫–∞–¥—Ä–∞
                UIGraphicsBeginImageContext(CGSizeMake(resolution, resolution));
                UIImage *testImage = UIGraphicsGetImageFromCurrentImageContext();
                UIGraphicsEndImageContext();
                
                NSData *maskData = [segmentation segmentImage:testImage withResolution:resolution];
                if (maskData && maskData.length == bufferSize) {
                    memcpy(outputBuffer, maskData.bytes, bufferSize);
                }
                return;
            }
            
            // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º CVPixelBuffer ‚Üí UIImage
            CIImage *ciImage = [CIImage imageWithCVPixelBuffer:pixelBuffer];
            CIContext *context = [CIContext contextWithOptions:nil];
            CGImageRef cgImage = [context createCGImage:ciImage fromRect:ciImage.extent];
            UIImage *cameraImage = [UIImage imageWithCGImage:cgImage];
            CGImageRelease(cgImage);
            
            // –í—ã–ø–æ–ª–Ω—è–µ–º inference –Ω–∞ –†–ï–ê–õ–¨–ù–û–ú –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∫–∞–º–µ—Ä—ã
            NSData *maskData = [segmentation segmentImage:cameraImage withResolution:resolution];
            
            if (maskData && maskData.length == bufferSize) {
                memcpy(outputBuffer, maskData.bytes, bufferSize);
                NSLog(@"[CoreML ‚Üí Unity] ‚úÖ –ú–∞—Å–∫–∞ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ (REAL CAMERA) (%d bytes)", bufferSize);
            } else {
                NSLog(@"[CoreML] ‚ùå –†–∞–∑–º–µ—Ä –º–∞—Å–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: %lu != %d", 
                      (unsigned long)maskData.length, bufferSize);
            }
        }
    }
    
    // –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    void CoreML_SegmentImage(const char* imagePath, uint8_t* outputBuffer, int bufferSize, int resolution) {
        @autoreleasepool {
            NSString *path = [NSString stringWithUTF8String:imagePath];
            NSLog(@"[Unity ‚Üí CoreML] SegmentImage called: %@", path);
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            
            // –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            UIImage *image = [UIImage imageWithContentsOfFile:path];
            if (!image) {
                NSLog(@"[CoreML] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: %@", path);
                return;
            }
            
            // Inference
            NSData *maskData = [segmentation segmentImage:image withResolution:resolution];
            
            if (maskData && maskData.length == bufferSize) {
                memcpy(outputBuffer, maskData.bytes, bufferSize);
                NSLog(@"[CoreML ‚Üí Unity] ‚úÖ –ú–∞—Å–∫–∞ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ (%d bytes)", bufferSize);
            }
        }
    }
    
    // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
    void CoreML_Cleanup() {
        @autoreleasepool {
            NSLog(@"[Unity ‚Üí CoreML] Cleanup called");
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            [segmentation cleanup];
        }
    }
    
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    bool CoreML_IsInitialized() {
        @autoreleasepool {
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            return segmentation.isInitialized;
        }
    }
    
    // –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ü—Ä–∏–Ω–∏–º–∞–µ—Ç frame –∏–∑ Unity Texture2D (RGB24 byte array)
    void CoreML_SetARFrameFromTexture(uint8_t* pixelData, int width, int height) {
        @autoreleasepool {
            static int frameCount = 0;
            frameCount++;
            
            if (frameCount == 1) {
                NSLog(@"[Unity ‚Üí CoreML] ‚úÖ –ü–æ–ª—É—á–∞–µ–º –∫–∞–¥—Ä—ã –∏–∑ Texture2D!");
                NSLog(@"[Unity ‚Üí CoreML] –†–∞–∑–º–µ—Ä: %dx%d, format: RGB24", width, height);
            }
            
            // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫–∞–¥—Ä
            if (currentARFrame != nil) {
                CVPixelBufferRelease(currentARFrame);
                currentARFrame = nil;
            }
            
            // ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–´–ô –°–ü–û–°–û–ë: –°–æ–∑–¥–∞–µ–º UIImage –Ω–∞–ø—Ä—è–º—É—é –∏–∑ NSData
            // –≠—Ç–æ –∏–∑–±–µ–≥–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º —Å bytes per row alignment
            NSData *imageData = [NSData dataWithBytes:pixelData length:(width * height * 3)];
            
            // –°–æ–∑–¥–∞–µ–º CGDataProvider –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            CGDataProviderRef provider = CGDataProviderCreateWithCFData((__bridge CFDataRef)imageData);
            
            // –°–æ–∑–¥–∞–µ–º CGImage –Ω–∞–ø—Ä—è–º—É—é (–±–µ–∑ CGContext)
            CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
            
            CGImageRef cgImage = CGImageCreate(
                width,                          // width
                height,                         // height
                8,                              // bits per component
                24,                             // bits per pixel (RGB = 8*3)
                width * 3,                      // bytes per row
                colorSpace,                     // color space
                kCGBitmapByteOrderDefault,      // bitmap info (–±–µ–∑ alpha)
                provider,                       // data provider
                NULL,                           // decode
                false,                          // should interpolate
                kCGRenderingIntentDefault       // intent
            );
            
            if (cgImage == NULL) {
                NSLog(@"[CoreML] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CGImage");
                CGColorSpaceRelease(colorSpace);
                CGDataProviderRelease(provider);
                return;
            }
            
            // –°–æ–∑–¥–∞–µ–º UIImage –∏–∑ CGImage
            UIImage *cameraImage = [UIImage imageWithCGImage:cgImage];
            
            // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ "—Ç–µ–∫—É—â–∏–π AR frame" (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ CVPixelBuffer –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            NSDictionary *options = @{
                (NSString *)kCVPixelBufferCGImageCompatibilityKey: @YES,
                (NSString *)kCVPixelBufferCGBitmapContextCompatibilityKey: @YES
            };
            
            CVPixelBufferRef pixelBuffer = NULL;
            CVPixelBufferCreate(
                kCFAllocatorDefault,
                width,
                height,
                kCVPixelFormatType_32BGRA,
                (__bridge CFDictionaryRef)options,
                &pixelBuffer
            );
            
            if (pixelBuffer != NULL) {
                CVPixelBufferLockBaseAddress(pixelBuffer, 0);
                void *baseAddress = CVPixelBufferGetBaseAddress(pixelBuffer);
                
                CGContextRef pixelContext = CGBitmapContextCreate(
                    baseAddress,
                    width,
                    height,
                    8,
                    CVPixelBufferGetBytesPerRow(pixelBuffer),
                    colorSpace,
                    kCGImageAlphaNoneSkipFirst | kCGBitmapByteOrderDefault
                );
                
                CGContextDrawImage(pixelContext, CGRectMake(0, 0, width, height), cgImage);
                CGContextRelease(pixelContext);
                CVPixelBufferUnlockBaseAddress(pixelBuffer, 0);
                
                currentARFrame = pixelBuffer;  // –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ CoreML_SegmentCurrentFrame
                
                if (frameCount % 50 == 0) {
                    NSLog(@"[CoreML] ‚ÑπÔ∏è –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ %d –∫–∞–¥—Ä–æ–≤ –∏–∑ Texture2D", frameCount);
                }
            }
            
            // Cleanup
            CGImageRelease(cgImage);
            CGDataProviderRelease(provider);
            CGColorSpaceRelease(colorSpace);
        }
    }
}


