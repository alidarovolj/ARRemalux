//
//  CoreMLSegmentation.mm
//  ARRemalux - CoreML Semantic Segmentation Plugin for Unity
//
//  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç SegFormer-B0 –º–æ–¥–µ–ª—å –¥–ª—è pixel-level –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å—Ü–µ–Ω—ã
//  –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 150 –∫–ª–∞—Å—Å–æ–≤ ADE20K dataset (wall, door, person, furniture, etc.)
//

#import <Foundation/Foundation.h>
#import <CoreML/CoreML.h>
#import <Vision/Vision.h>
#import <ARKit/ARKit.h>
#import <UIKit/UIKit.h>

// ===============================
// MARK: - CoreML Segmentation Class
// ===============================

@interface CoreMLSegmentation : NSObject

@property (nonatomic, strong) MLModel *mlModel;
@property (nonatomic, strong) VNCoreMLModel *visionModel;
@property (nonatomic, strong) VNCoreMLRequest *segmentationRequest;
@property (nonatomic, assign) BOOL isInitialized;

+ (instancetype)sharedInstance;
- (BOOL)initializeWithModelPath:(NSString *)modelPath;
- (NSData *)segmentImage:(UIImage *)image withResolution:(NSInteger)resolution;
- (void)cleanup;

@end

@implementation CoreMLSegmentation

// Singleton instance
+ (instancetype)sharedInstance {
    static CoreMLSegmentation *instance = nil;
    static dispatch_once_t onceToken;
    dispatch_once(&onceToken, ^{
        instance = [[CoreMLSegmentation alloc] init];
    });
    return instance;
}

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CoreML –º–æ–¥–µ–ª–∏
- (BOOL)initializeWithModelPath:(NSString *)modelPath {
    NSLog(@"[CoreMLSegmentation] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –º–æ–¥–µ–ª—å—é: %@", modelPath);
    
    @try {
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        if (![[NSFileManager defaultManager] fileExistsAtPath:modelPath]) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: %@", modelPath);
            return NO;
        }
        
        // –ó–∞–≥—Ä—É–∑–∫–∞ CoreML –º–æ–¥–µ–ª–∏
        NSURL *modelURL = [NSURL fileURLWithPath:modelPath];
        NSError *error = nil;
        
        // –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        NSURL *compiledURL = [MLModel compileModelAtURL:modelURL error:&error];
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
            return NO;
        }
        
        // –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        self.mlModel = [MLModel modelWithContentsOfURL:compiledURL error:&error];
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
            return NO;
        }
        
        // –°–æ–∑–¥–∞–Ω–∏–µ Vision –º–æ–¥–µ–ª–∏
        self.visionModel = [VNCoreMLModel modelForMLModel:self.mlModel error:&error];
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è Vision –º–æ–¥–µ–ª–∏: %@", error.localizedDescription);
            return NO;
        }
        
        // –°–æ–∑–¥–∞–Ω–∏–µ Vision request –¥–ª—è segmentation
        self.segmentationRequest = [[VNCoreMLRequest alloc] initWithModel:self.visionModel];
        self.segmentationRequest.imageCropAndScaleOption = VNImageCropAndScaleOptionScaleFill;
        
        self.isInitialized = YES;
        NSLog(@"[CoreMLSegmentation] ‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ!");
        
        // –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
        NSLog(@"[CoreMLSegmentation] Model Description: %@", self.mlModel.modelDescription);
        
        return YES;
    }
    @catch (NSException *exception) {
        NSLog(@"[CoreMLSegmentation] ‚ùå Exception –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: %@", exception.reason);
        return NO;
    }
}

// –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- (NSData *)segmentImage:(UIImage *)image withResolution:(NSInteger)resolution {
    if (!self.isInitialized) {
        NSLog(@"[CoreMLSegmentation] ‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!");
        return nil;
    }
    
    @try {
        // –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è inference
        CFAbsoluteTime startTime = CFAbsoluteTimeGetCurrent();
        
        // –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: –∏–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ resolution√óresolution
        UIImage *resizedImage = [self resizeImage:image toSize:CGSizeMake(resolution, resolution)];
        
        // –°–æ–∑–¥–∞–Ω–∏–µ VNImageRequestHandler
        CIImage *ciImage = [CIImage imageWithCGImage:resizedImage.CGImage];
        VNImageRequestHandler *handler = [[VNImageRequestHandler alloc] 
                                          initWithCIImage:ciImage 
                                          options:@{}];
        
        // –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ inference
        NSError *error = nil;
        [handler performRequests:@[self.segmentationRequest] error:&error];
        
        if (error) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –û—à–∏–±–∫–∞ inference: %@", error.localizedDescription);
            return nil;
        }
        
        // –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        VNCoreMLFeatureValueObservation *observation = self.segmentationRequest.results.firstObject;
        if (!observation) {
            NSLog(@"[CoreMLSegmentation] ‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ inference");
            return nil;
        }
        
        // –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑ MLMultiArray
        MLMultiArray *segmentationMap = observation.featureValue.multiArrayValue;
        
        // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è MLMultiArray ‚Üí byte array
        NSData *maskData = [self convertMultiArrayToByteArray:segmentationMap 
                                                  withResolution:resolution];
        
        // –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
        CFAbsoluteTime elapsedTime = CFAbsoluteTimeGetCurrent() - startTime;
        NSLog(@"[CoreMLSegmentation] ‚ö° Inference time: %.1f ms", elapsedTime * 1000.0);
        
        return maskData;
    }
    @catch (NSException *exception) {
        NSLog(@"[CoreMLSegmentation] ‚ùå Exception –ø—Ä–∏ segmentation: %@", exception.reason);
        return nil;
    }
}

// –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- (UIImage *)resizeImage:(UIImage *)image toSize:(CGSize)newSize {
    UIGraphicsBeginImageContextWithOptions(newSize, NO, 1.0);
    [image drawInRect:CGRectMake(0, 0, newSize.width, newSize.height)];
    UIImage *resizedImage = UIGraphicsGetImageFromCurrentImageContext();
    UIGraphicsEndImageContext();
    return resizedImage;
}

// –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è MLMultiArray ‚Üí byte array (–º–∞—Å–∫–∞ –∫–ª–∞—Å—Å–æ–≤)
- (NSData *)convertMultiArrayToByteArray:(MLMultiArray *)multiArray 
                          withResolution:(NSInteger)resolution {
    NSInteger totalElements = resolution * resolution;
    NSMutableData *data = [NSMutableData dataWithLength:totalElements];
    uint8_t *bytes = (uint8_t *)data.mutableBytes;
    
    // SegFormer –≤—ã–¥–∞—ë—Ç argmax –∫–ª–∞—Å—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∏–∫—Å–µ–ª—è
    // –§–æ—Ä–º–∞ –≤—ã–≤–æ–¥–∞: [1, num_classes, height, width]
    // –ù–∞–º –Ω—É–∂–µ–Ω argmax –ø–æ –æ—Å–∏ num_classes
    
    for (NSInteger i = 0; i < totalElements; i++) {
        // –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        // –î–ª—è SegFormer —ç—Ç–æ —É–∂–µ argmax –≤—ã–≤–æ–¥
        NSNumber *classId = [multiArray objectAtIndexedSubscript:i];
        bytes[i] = [classId unsignedCharValue];
    }
    
    return data;
}

// –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
- (void)cleanup {
    self.mlModel = nil;
    self.visionModel = nil;
    self.segmentationRequest = nil;
    self.isInitialized = NO;
    NSLog(@"[CoreMLSegmentation] üßπ –†–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã");
}

@end

// ===============================
// MARK: - Unity C Bridge
// ===============================

extern "C" {
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    bool CoreML_Initialize(const char* modelPath) {
        @autoreleasepool {
            NSString *path = [NSString stringWithUTF8String:modelPath];
            NSLog(@"[Unity ‚Üí CoreML] Initialize called with path: %@", path);
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            BOOL success = [segmentation initializeWithModelPath:path];
            
            return success;
        }
    }
    
    // –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ç–µ–∫—É—â–µ–≥–æ AR –∫–∞–¥—Ä–∞
    void CoreML_SegmentCurrentFrame(uint8_t* outputBuffer, int bufferSize, int resolution) {
        @autoreleasepool {
            NSLog(@"[Unity ‚Üí CoreML] SegmentCurrentFrame called (resolution: %d)", resolution);
            
            // TODO: –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π AR frame –∏–∑ ARSession
            // –î–ª—è –Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º placeholder
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            
            if (!segmentation.isInitialized) {
                NSLog(@"[CoreML] ‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!");
                return;
            }
            
            // –í–†–ï–ú–ï–ù–ù–û–ï –†–ï–®–ï–ù–ò–ï: —Å–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            // –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å AR camera frame
            UIImage *testImage = [UIImage imageNamed:@"test.jpg"];
            if (!testImage) {
                // –°–æ–∑–¥–∞—ë–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∞
                UIGraphicsBeginImageContext(CGSizeMake(resolution, resolution));
                testImage = UIGraphicsGetImageFromCurrentImageContext();
                UIGraphicsEndImageContext();
            }
            
            // –í—ã–ø–æ–ª–Ω—è–µ–º inference
            NSData *maskData = [segmentation segmentImage:testImage withResolution:resolution];
            
            if (maskData && maskData.length == bufferSize) {
                // –ö–æ–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Unity buffer
                memcpy(outputBuffer, maskData.bytes, bufferSize);
                NSLog(@"[CoreML ‚Üí Unity] ‚úÖ –ú–∞—Å–∫–∞ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ (%d bytes)", bufferSize);
            } else {
                NSLog(@"[CoreML] ‚ùå –†–∞–∑–º–µ—Ä –º–∞—Å–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: %lu != %d", 
                      (unsigned long)maskData.length, bufferSize);
            }
        }
    }
    
    // –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    void CoreML_SegmentImage(const char* imagePath, uint8_t* outputBuffer, int bufferSize, int resolution) {
        @autoreleasepool {
            NSString *path = [NSString stringWithUTF8String:imagePath];
            NSLog(@"[Unity ‚Üí CoreML] SegmentImage called: %@", path);
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            
            // –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            UIImage *image = [UIImage imageWithContentsOfFile:path];
            if (!image) {
                NSLog(@"[CoreML] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: %@", path);
                return;
            }
            
            // Inference
            NSData *maskData = [segmentation segmentImage:image withResolution:resolution];
            
            if (maskData && maskData.length == bufferSize) {
                memcpy(outputBuffer, maskData.bytes, bufferSize);
                NSLog(@"[CoreML ‚Üí Unity] ‚úÖ –ú–∞—Å–∫–∞ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ (%d bytes)", bufferSize);
            }
        }
    }
    
    // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
    void CoreML_Cleanup() {
        @autoreleasepool {
            NSLog(@"[Unity ‚Üí CoreML] Cleanup called");
            
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            [segmentation cleanup];
        }
    }
    
    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    bool CoreML_IsInitialized() {
        @autoreleasepool {
            CoreMLSegmentation *segmentation = [CoreMLSegmentation sharedInstance];
            return segmentation.isInitialized;
        }
    }
}


