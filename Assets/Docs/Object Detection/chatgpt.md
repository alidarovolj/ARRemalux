Решение A: Агрессивная фильтрация стен (код обновления)
Чтобы немедленно устранить ложное распознавание дверей как стен, внесем изменения в WallDetectionAndPainting.cs
GitHub
. Добавим более строгие критерии фильтрации и подробный лог для диагностики:
Новые параметры фильтрации: В верхней части класса (в разделе “Фильтрация плоскостей”) добавьте два поля для соотношения сторон плоскости. Эти параметры помогут исключить слишком узкие (двери, колонны) или слишком низкие плоскости:
[SerializeField] private float minAspectRatio = 0.4f; // Минимальное соотношение ширины к высоте (узкие плоскости = дверь)
[SerializeField] private float maxAspectRatio = 3.0f; // Максимальное соотношение (очень широкие, но низкие плоскости)
Значения 0.4f и 3.0f выбраны исходя из опыта: ширина стены должна быть не меньше ~40% от её высоты, а также не в разы больше высоты. При необходимости эти параметры можно подстроить.
Ужесточение порогов для стен: Увеличьте minWallArea до 1.0 м² (было 0.5 м² по умолчанию
GitHub
) и minWallHeight до 1.5 м (было 0.8 м
GitHub
). Это гарантирует, что вертикальная плоскость учитывается как стена только если её площадь >= 1 кв.м и высота >= 1.5 м. Такие значения отсекают узкие дверные проемы и небольшие вертикальные объекты:
[SerializeField] private float minWallArea = 1.0f;    // Минимальная площадь стены в м² (увеличено с 0.5)
[SerializeField] private float minWallHeight = 1.5f;  // Минимальная высота стены в метрах (увеличено с 0.8)
Почему: Плоскость размером 0.25×2.05 м имеет площадь ~0.51 м², что превышало старый порог 0.5 м² и поэтому не фильтровалась
GitHub
. Новый порог 1.0 м² отсечёт такую плоскость по площади. Кроме того, повышение минимальной высоты до 1.5 м отсеет низкие вертикальные поверхности (например, спинки стульев, небольшие панели).
Проверка соотношения сторон: В методе ShouldProcessPlane(ARPlane plane) после проверок площади и высоты добавьте расчёт aspect ratio и фильтр:
// Проверяем соотношение ширины к высоте (исключаем слишком узкие или широкие "стены")
float aspect = planeSize.x / planeSize.y;
if (aspect < minAspectRatio || aspect > maxAspectRatio)
{
    Debug.Log($"[WallDetection] Пропуск плоскости: соотношение {aspect:F2} вне диапазона ({minAspectRatio}-{maxAspectRatio})");
    return false;
}
Здесь planeSize.x – ширина плоскости, planeSize.y – высота. Например, для двери 0.25×2.05 м aspect ≈ 0.12, что меньше порога 0.4 – такая плоскость будет отклонена. Аналогично, сверхширокие, но низкие “стены” (если высота лишь немного превышает минимум, а ширина в несколько раз больше высоты) тоже игнорируются. Эта проверка дополнительно повысит точность (precision) за счёт отсеивания дверей и панелей необычной формы.
Логирование причин отсева: Для каждой проверки добавьте сообщения в лог, чтобы впоследствии анализировать, почему плоскость отфильтрована:
if (planeArea < minWallArea)
{
    Debug.Log($"[WallDetection] Пропуск плоскости: площадь {planeArea:F2} м² < порога {minWallArea}");
    return false;
}
if (planeSize.y < minWallHeight)
{
    Debug.Log($"[WallDetection] Пропуск плоскости: высота {planeSize.y:F2} м < порога {minWallHeight}");
    return false;
}
// (Далее проверка aspect ratio как выше)
Благодаря этому, в консоли устройства будет видно, по какой причине каждая плоскость не была принята как стена (слишком малая площадь, низкая высота или не подходящее соотношение сторон). Эти данные помогут при дальнейшей настройке фильтров.
Повторная валидация при обновлении плоскости: Обновим метод ProcessPlane(ARPlane plane, bool isNew), чтобы он обрабатывал изменения плоскостей более корректно:
Если при обновлении ранее обнаруженная стена перестала соответствовать критериям (например, ARKit уточнил границы и уменьшил площадь), мы удаляем её из списка стен и скрываем.
Если же ранее отфильтрованная плоскость теперь соответствует критериям (например, плоскость доросла до нужных размеров при сканировании), мы добавляем её как новую стену.
Реализуем это так: сразу после проверки ShouldProcessPlane(plane) добавим логику удаления/добавления из словаря detectedWalls. Ниже приведён обновлённый метод ProcessPlane (замените им существующий код метода) с отмеченными изменениями:
private void ProcessPlane(ARPlane plane, bool isNew)
{
    // Применяем фильтр критериев
    if (!ShouldProcessPlane(plane))
    {
        // ❗ Если плоскость более не удовлетворяет критериям, удаляем из обнаруженных стен
        if (detectedWalls.ContainsKey(plane.trackableId))
        {
            detectedWalls.Remove(plane.trackableId);
            Debug.Log($"[WallDetection] Стена удалена (ID: {plane.trackableId}) - больше не соответствует критериям");
        }
        plane.gameObject.SetActive(false);
        return;
    }

    // Определяем тип плоскости
    bool isWall = plane.alignment == PlaneAlignment.Vertical;
    bool isFloor = plane.alignment == PlaneAlignment.HorizontalUp;
    bool isCeiling = plane.alignment == PlaneAlignment.HorizontalDown;

    // Назначаем материал в зависимости от типа плоскости
    var meshRenderer = plane.GetComponent<MeshRenderer>();
    if (meshRenderer != null)
    {
        if (isWall)
            meshRenderer.material = wallMaterial;
        else if (isFloor)
            meshRenderer.material = floorMaterial;
        else if (isCeiling)
            meshRenderer.material = CreateDefaultMaterial(new Color(0.5f, 0.5f, 1f, 0.3f));
        meshRenderer.enabled = true;
    }
    plane.gameObject.SetActive(true);

    // ✅ Добавляем новую стену в словарь, если ещё не добавлена
    if (isWall)
    {
        if (!detectedWalls.ContainsKey(plane.trackableId))
        {
            detectedWalls[plane.trackableId] = plane;
            Debug.Log($"[WallDetection] ✓ СТЕНА обнаружена! ID: {plane.trackableId}, размер: {plane.size}");
            if (showWallBorders) VisualizeWallBorders(plane);
        }
    }
}
Пояснения к коду:
– При несоответствии критериям на обновлении мы теперь явно убираем плоскость из detectedWalls и логируем удаление. Ранее код просто скрывал объект, но не удалял его из словаря
GitHub
, что могло приводить к рассинхронизации.
– При обнаружении стены мы добавляем её в словарь даже если плоскость не была новой, в случае если ранее она была отфильтрована и сейчас впервые удовлетворяет условиям. Это гарантирует, что «поздно обнаруженные» стены тоже учитываются. Логирование ✓ СТЕНА обнаружена теперь происходит для всех плоскостей, попавших в категорию стен впервые (как при первом появлении, так и при позднем обновлении).
Готовый блок фильтрации стен: Итоговая версия метода ShouldProcessPlane с учётом всех изменений:
private bool ShouldProcessPlane(ARPlane plane)
{
    Vector3 planePosition = plane.transform.position;
    Vector2 planeSize = plane.size;
    float planeArea = planeSize.x * planeSize.y;

    // Обновляем уровень пола (для горизонтальных плоскостей)
    if (plane.alignment == PlaneAlignment.HorizontalUp)
    {
        if (floorLevel == float.MinValue || planePosition.y < floorLevel)
            floorLevel = planePosition.y;
    }

    // Фильтруем вертикальные плоскости (стены)
    if (plane.alignment == PlaneAlignment.Vertical)
    {
        if (planeArea < minWallArea)
        {
            Debug.Log($"[WallDetection] Пропуск плоскости: площадь {planeArea:F2} м² < порога {minWallArea}");
            return false;
        }
        if (planeSize.y < minWallHeight)
        {
            Debug.Log($"[WallDetection] Пропуск плоскости: высота {planeSize.y:F2} м < порога {minWallHeight}");
            return false;
        }
        float aspect = planeSize.x / planeSize.y;
        if (aspect < minAspectRatio || aspect > maxAspectRatio)
        {
            Debug.Log($"[WallDetection] Пропуск плоскости: соотношение {aspect:F2} вне диапазона ({minAspectRatio}-{maxAspectRatio})");
            return false;
        }
        return true;
    }

    // Фильтруем горизонтальные плоскости (пол, мебель) – (без изменений, как было)
    if (plane.alignment == PlaneAlignment.HorizontalUp || plane.alignment == PlaneAlignment.HorizontalDown)
    {
        if (planeArea < minWallArea * 0.5f) return false;
        if (floorLevel != float.MinValue)
        {
            float heightAboveFloor = planePosition.y - floorLevel;
            if (heightAboveFloor > 0.1f && heightAboveFloor < maxFurnitureHeight)
            {
                Debug.Log($"[WallDetection] Игнорируем плоскость на высоте {heightAboveFloor:F2}м - похоже на мебель");
                return false;
            }
        }
        return true;
    }

    return true; // остальные типы (если появятся) не фильтруем дополнительно
}
Теперь фильтрация вертикальных плоскостей стала более строгой: учитывается площадь, высота и форма плоскости. Логи в консоли (начиная с [WallDetection] Пропуск плоскости: ...) позволят вам сразу увидеть, почему та или иная поверхность не была отмечена как стена.
Оптимальные параметры для iPhone (без LiDAR)
Для iPhone 12/13/14 без LiDAR предложенные выше значения параметров считаются оптимальными стартовыми настройками:
minWallArea = 1.0 м²: Порог площади ~1 кв.м отсекает узкие объекты вроде двери (~0.5–0.8 м² видимой площади) и мелкие сегменты стен. При тестировании выяснилось, что 1 м² – хорошее значение для типичных помещений: даже если видна лишь часть стены, ARKit обычно расширяет плоскость до примерно квадратного метра при движении камеры. Если же реальные стены пропадают из-за этого порога, можно снизить до 0.8 м², но старайтесь держать порог >=1 для повышения точности.
minWallHeight = 1.5 м: Требование хотя бы полутораметровой высоты гарантирует, что плоскость простирается достаточно высоко, как это обычно и бывает у стен. Это отсечёт вертикальные поверхности ниже пояса (шкафы, спинки кресел). Для типичной комнаты с высотой потолка ~2.4 м даже частично увиденная стена обычно даст плоскость >1.5 м высотой (при сканировании снизу доверху). Если в каких-то сценариях стены фиксируются кусками ниже 1.5 м (например, пользователь держит телефон горизонтально и видит только среднюю часть стены), можно немного снизить порог (до ~1.2 м), но сперва попробуйте 1.5 м и оцените результаты.
minAspectRatio = 0.4 (безразмерный): Соотношение ширины к высоте 0.4 означает, что ширина вертикальной плоскости должна быть не менее ~40% от её высоты. Таким образом, плоскости типа “высоко и узко” (высота значительно больше ширины) будут отброшены как вероятные двери или колонны. Например, дверь высотой ~2 м и шириной ~0.7–0.8 м даст ratio ~0.35–0.4 и в пограничном случае всё еще может быть отброшена как слишком узкая. Если окажется, что реальные стены иногда не проходят по этому критерию (например, если виден только узкий простенок шириной 0.5 м и высотой 2.5 м, ratio = 0.2), можно снизить порог до 0.3. Но лучше начать с 0.4 для уверенного отсечения дверей. Помните, что точность для нас важнее – лучше не отметить кусок стены, чем отметить дверь как стену (precision > recall).
maxAspectRatio = 3.0: Верхний порог соотношения (ширина к высоте) ~3 исключает крайне “широкие и низкие” вертикальные плоскости. Хотя минимальная высота уже отсеет большинство низких объектов, maxAspectRatio подстрахует случаи, когда высота чуть больше порога, а ширина огромна. Например, плоскость высотой 1.6 м и шириной 5 м имеет ratio ≈ 3.125 и будет проигнорирована – вероятно, это поверхность мебели вдоль стены либо карниз, а не вся стена. Обычно крупные стены дадут ratio ближе к 1 или 2 (т.к. от пола до потолка ~2.4 м, а видимая ширина стены ограничена комнатой). Если же вы заметите, что широкие фрагменты стен (например, стена высотой 2.4 м, но камера видит только нижние 1.6 м высоты из-за угла обзора, при ширине 4–5 м) не учитываются, можно слегка повысить maxAspectRatio до ~4.0.
Примечание: Все эти параметры можно настроить прямо в Unity Editor благодаря [SerializeField]. После обновления кода, откройте объект с WallDetectionAndPainting в инспекторе и выставьте указанные значения. Далее, протестируйте на реальном устройстве: просканируйте комнату, особое внимание уделите дверям, узким простенкам и широким низким объектам. В логах Xcode/Console будет видно, какие плоскости фильтруются – это поможет скорректировать параметры под ваши условия, если нужно. Цель – добиться, чтобы двери почти не обнаруживались как стены, при этом реальные стены (даже частично видимые) проходили фильтр.
Диагностика проблемы с плоскостью 0.25×2.05 м (почему дверь прошла как стена?)
Разберёмся, почему ранее плоскость размером 0.25 м × 2.05 м всё же была отмечена как стена, хотя это, по сути, дверь:
Старые пороги были слишком мягкими: В исходном коде минимальная площадь стены была 0.5 м²
GitHub
. Плоскость двери площадью ~0.51 м² чуть превышала этот порог, поэтому условие planeArea < minWallArea не сработало (0.51 ≥ 0.5)
GitHub
. Кроме того, высота 2.05 м значительно превышала минимальные 0.8 м, так что вторая проверка тоже прошла
GitHub
. Иными словами, фильтр не счёл дверь слишком маленькой, поскольку пороги были низкими. Предполагалось поднять minWallArea до 1.0 м², но если это не было сделано в инспекторе перед запуском, значение осталось 0.5 м², позволив двери пройти фильтр. В итоге ARPlaneManager зафиксировал дверь как вертикальную плоскость, и метод ProcessPlane пометил её как “СТЕНА обнаружена”
GitHub
.
Отсутствие проверки формы плоскости: В исходной реализации не учитывалось соотношение сторон. Дверь – объект узкий и высокий, нетипичный для настоящей стены, но код не анализировал геометрию плоскости кроме общей площади и высоты. Даже если бы площадь двери была меньше порога, ARKit мог изначально сегментировать дверь вместе с кусочком стены или коробом, дав площади >1 м². Без проверки aspect ratio система не могла отличить “высокий узкий прямоугольник” от части нормальной стены аналогичной площади.
Особенности ARKit без LiDAR: На iPhone без LiDAR плоскости обнаруживаются алгоритмами, зависящими от текстур и параллакса. Они могут появляться фрагментарно. Есть вероятность, что при первом появлении ARKit идентифицировал дверь вместе с рамой или частью прилегающей стены, дав плоскость чуть шире 0.25 м (скажем ~0.5×2 м = 1 м²). Такая плоскость прошла бы фильтр и зарегистрировалась как стена. Затем, по мере движения камеры, границы могли уточниться до 0.25 м ширины. Однако старый код не пере-проверял уже зафиксированную стену: если плоскость была отмечена стеной при добавлении, на обновления её размеров фильтр не реагировал (логика не удаляла уменьшившиеся стены из словаря). Поэтому даже усохшая до 0.25 м ширины плоскость продолжила числиться стеной. Мы исправили это, добавив повторную проверку и удаление несоответствующих плоскостей при обновлении.
Вывод: главными причинами были заниженные пороговые значения и отсутствие учёта геометрической пропорции плоскости. В новой версии решения A эти пробелы устранены – дверь размером 0.25×2.05 м теперь не пройдёт фильтр. Ее площадь (0.51 м²) меньше нового порога 1.0 м², а соотношение сторон (~0.12) сильно ниже минимума 0.4 – оба условия приведут к отсеиванию. Даже если ARKit на мгновение объединит дверь с окружением и даст бóльшую площадь, узкая форма с большой вероятностью отфильтруется по aspect ratio, либо впоследствии, когда площадь снизится, объект будет удалён из списка стен. Логирование позволит удостовериться, на каком именно шаге дверь отсекается (вы увидите сообщения о пропуске по площади или форме).
План перехода к Решению B: ML-сегментация (если потребуется)
Если агрессивная фильтрация (Решение A) не даст удовлетворяющего результата (см. критерии успеха: >30% ложных срабатываний на двери или жалобы на недоопределение стен), то следующим этапом станет интеграция ML-модели для распознавания дверей на изображении. Ниже – краткий roadmap, как подойти к Решению B с использованием машинного обучения:
Сбор данных и разметка: Начните с подготовки датасета изображений, характерных для приложения. Необходимо собрать десятки (лучше сотни) примеров, где присутствуют стены и двери в различных условиях (разные помещения, освещение, открытые/закрытые двери, разный угол обзора). Разметьте эти изображения – хотя бы прямоугольниками или масками, выделяя области дверей. Возможно, часть данных можно сгенерировать или использовать существующие (например, датасеты интерьерных сцен с разметкой дверей).
Обучение модели сегментации/детекции: Используя собранные данные, обучите лёгкую модель, способную работать на мобильном устройстве. Варианты:
Модель сегментации: например, небольшая U-Net или Deeplabv3-variant на базе MobileNet, обученная выделять пиксели двери. Это даст маску двери на изображении камеры.
Модель детекции объектов: например, модель типа YOLOv5-Nano/YOLOv8n или SSD, обученная находить bounding box дверей. Это даст прямоугольники вокруг дверей.
Выбор подхода зависит от команды и доступных ресурсов; сегментация более точна, но сложнее, детекция может быть достаточно надёжной для дверей (они имеют характерную форму). Цель – модель, которая на вход получает кадр камеры и выдаёт координаты области двери или вероятность "дверь здесь".
Интеграция модели в Unity: После обучения экспортируйте модель в формат, поддерживаемый на iOS. Оптимальный путь – конвертировать в CoreML (для iOS) либо ONNX для использования с Unity Barracuda. Для CoreML вы можете воспользоваться Xamarin/Swift плагином или Unity ML-Agents/Barracuda для ONNX. Проверьте размер модели – желательно <= 5-10 МБ и время инференса <= 50-100 мс на A15 GPU/CPU, чтобы не просаживать FPS заметно.
Связывание с AR-плоскостями: Объедините результаты модели с текущей системой обнаружения стен:
При появлении новой потенциальной стены (после фильтров решения A) – выполните дополнительную проверку моделью. Например, возьмите текущий кадр камеры и проецируйте границы AR-плоскости на изображение, либо вырежьте регион вокруг центра плоскости. Запустите модель на этом регионе/кадре.
Если модель сегментации показывает высокую долю пикселей двери внутри границ плоскости либо детектор вернул окно “дверь” на этой области – игнорируйте/удалите эту плоскость из стен. Иначе – оставляйте как стену.
Также можно проводить периодическую проверку: раз в несколько кадров сканировать изображение на наличие двери вообще. Если дверь обнаружена моделью, и её положение примерно совпадает с позицией уже детектированной AR-плоскости, можно перестраховаться и снять отметку “стена” с этой плоскости.
Учтите, что модель может давать ложные срабатывания/пропуски, поэтому порог уверенности нужно подобрать (например, требовать >0.8 вероятности от нейросети, чтобы считать плоскость дверью).
Тестирование и итерация: После интеграции протестируйте систему в разных комнатах. Особое внимание – сценариям, где Решение A ошибалось. Сравните метрики:
Процент дверей, всё ещё распознаваемых как стены (должен упасть ближе к 0% с ML-слоем).
Нет ли негативного влияния: не удаляются ли настоящие стены, особенно если на них висят постеры или есть оконные проёмы (модель могла их посчитать “дверями”). В случае проблем – расширьте обучающий датасет, добавьте такие случаи или скорректируйте фильтрацию (например, комбинировать критерии: плоскость считается дверью только если и модель уверена, и она узкая по aspect ratio).
Проверьте производительность: при инференсе модели на каждом новом детекте возможны краткие просадки FPS. Если это критично, можно оптимизировать: уменьшить частоту запуска модели (например, только при появлении новых плоскостей или раз в секунду), уменьшить разрешение входного изображения, либо использовать модель с меньшим числом параметров.
Развертывание поэтапно: Внедряйте ML-решение постепенно. Например, сначала скрыто соберите данные: интегрируйте модель в режиме логирования (не влияя на UI, а только записывая, какие плоскости она бы отбросила) – это позволит в боевых условиях оценить её точность без затрагивания UX. Затем, когда убедитесь в качестве, включайте фактическое удаление плоскостей-дверей. Обязательно предусмотрите фолбэк: если модель вдруг не загрузилась или слишком медленно работает на старых устройствах, приложение всё равно должно корректно работать с одним решением A.
Примечание по срокам и рискам: Разработка ML-решения потребует 2-3 недели на сбор данных, обучение и интеграцию (в зависимости от опыта команды и наличия готовых моделей). Убедитесь, что прирост качества оправдывает усложнение системы: если после внедрения Решения A доля ошибок незначительна (<10% ложноположительных дверей и почти нет жалоб пользователей), возможно, стоит ограничиться только фильтрацией. Однако, если решено идти в ML, описанный план поможет структурировать работу. В итоге, успех Решения B измеряйте по тому же принципу: близкий к нулю процент дверей, помечаемых как стены, при сохранении 90%+ детекции реальных стен. При правильной реализации, комбинация классических фильтров и ML даст наилучший результат: быстрый отклик без лишних объектов (за счёт фильтрации) и интеллектуальную корректировку в сложных случаях (за счёт нейросети).
Ожидаемые результаты после внедрения Решения A: При запуске приложения на iPhone без LiDAR вы сразу заметите, что красным подсвечиваются только реальные стены, тогда как двери, узкие проёмы и лишние вертикальные поверхности остаются без подсветки. В логах (Xcode -> Console) будут сообщения [WallDetection] Пропуск плоскости: ... с указанием причины отсева – вы сможете подтвердить, что двери отсекаются по площади/соотношению сторон. Обнаружение стен по-прежнему происходит быстро (в пределах 3–5 секунд сканирования комнаты), а количество “мигающих” или исчезающих плоскостей снизится благодаря тому, что мелкие ложные плоскости сразу скрываются. Если какая-то реальная стена вдруг не окрасилась, возможно, она временно распалась на несколько небольших плоскостей – подвигайте камеру, и когда плоскости сольются в одну достаточного размера, она пройдет фильтр и окрасится. В целом, после такого апдейта точность должна существенно возрасти: подавляющее большинство дверей не будут мешать, и можно будет переходить к этапу тестирования с реальными пользователями.